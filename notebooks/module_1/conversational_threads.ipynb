{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Threads Conversacionais"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Muitas aplicações LLM têm uma interface similar a chatbot na qual o usuário e a aplicação LLM se envolvem em uma conversa de múltiplas rodadas. Para rastrear essas conversas, você pode usar o recurso Threads no LangSmith.\n\nIsso é relevante para nossa aplicação RAG, que deve manter contexto de conversas anteriores com usuários."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Configuração"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Você pode defini-las diretamente\nimport os\nos.environ[\"GOOGLE_API_KEY\"] = \"\"\nos.environ[\"LANGSMITH_API_KEY\"] = \"\"\nos.environ[\"LANGSMITH_TRACING\"] = \"true\"\nos.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\"  # Se você não definir isso, os rastreamentos irão para o projeto Default"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Ou você pode usar um arquivo .env\nfrom dotenv import load_dotenv\nload_dotenv(dotenv_path=\"../../.env\", override=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Agrupar rastreamentos em threads"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Um Thread é uma sequência de rastreamentos representando uma única conversa. Cada resposta é representada como seu próprio rastreamento, mas esses rastreamentos são ligados juntos por fazer parte do mesmo thread.\n\nPara associar rastreamentos juntos, você precisa passar uma chave de metadados especial onde o valor é o identificador único para aquele thread.\n\nO valor da chave é o identificador único para aquela conversa. O nome da chave deve ser um dos seguintes:\n\n- session_id\n- thread_id\n- conversation_id.\n\nO valor deve ser um UUID."
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "thread_id = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from langsmith import traceable\nfrom typing import List\nimport nest_asyncio\nfrom utils import get_vector_db_retriever\nimport sys\nsys.path.append('../../')\nfrom gemini_utils import call_gemini_chat\n\nnest_asyncio.apply()\nretriever = get_vector_db_retriever()\n\n@traceable(run_type=\"chain\")\ndef retrieve_documents(question: str):\n    return retriever.invoke(question)\n\n@traceable(run_type=\"chain\")\ndef generate_response(question: str, documents):\n    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n    rag_system_prompt = \"\"\"Você é um assistente para tarefas de perguntas e respostas.\n    Use as seguintes partes do contexto recuperado para responder à pergunta mais recente na conversa.\n    Se você não souber a resposta, apenas diga que não sabe.\n    Use no máximo três frases e mantenha a resposta concisa.\n    \"\"\"\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": rag_system_prompt\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n        }\n    ]\n    return call_gemini(messages)\n\n@traceable(\n    run_type=\"llm\",\n    metadata={\n        \"ls_provider\": \"google\",\n        \"ls_model_name\": \"gemini-1.5-flash\"\n    }\n)\ndef call_gemini(\n    messages: List[dict], model: str = \"gemini-1.5-flash\", temperature: float = 0.0\n) -> str:\n    return call_gemini_chat(model, messages, temperature)\n\n@traceable(run_type=\"chain\")\ndef langsmith_rag(question: str):\n    documents = retrieve_documents(question)\n    response = generate_response(question, documents)\n    return response"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Agora vamos executar nossa aplicação duas vezes com este thread_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "question = \"Como adiciono metadados a um Rastreamento?\"\nai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"thread_id\": thread_id}})\nprint(ai_answer)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "question = \"Como posso adicionar tags a um Rastreamento?\"\nai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"thread_id\": thread_id}})\nprint(ai_answer)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Vamos dar uma olhada no LangSmith!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ls-academy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}